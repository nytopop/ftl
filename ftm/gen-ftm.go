// This file was automatically generated by genny.
// Any changes will be lost if this file is regenerated.
// see https://github.com/cheekybits/genny

package ftm

import (
	"sync"

	"github.com/nytopop/ftl"
)

// FTMBool exposes a thread-safe, mutable view into any
// value of type bool.
//
// Internally, nested mutexes are used instead of the
// usual retry mechanism.
type FTMBool interface {
	// Mut returns a pointer to a safely mutable bool.
	//
	// This reference must not escape the transaction
	// in which it was created.
	Mut() *bool

	// Discard any changes since the last checkpoint.
	Discard()

	open() FTMBool
	atomic(TxBool) ftl.Closure
}

// FTMBoolV exposes an opaque view into any value of
// type bool. Reading or writing the value requires
// the use of a call to atomic.
type FTMBoolV interface {
	Atomic(TxBool) ftl.Closure
}

type ftmBool struct {
	orig bool
	mut  *bool
	mu   sync.Mutex
}

func newFTMBool(v bool) *ftmBool {
	return &ftmBool{
		orig: v,
		mut:  &v,
	}
}

func NewFTMBoolV(v bool) FTMBoolV {
	return newFTMBool(v)
}

func (s *ftmBool) Mut() *bool {
	return s.mut
}

func (s *ftmBool) Discard() {
	*s.mut = s.orig
}

func (s *ftmBool) open() FTMBool {
	return &ftmBool{
		orig: *s.mut,
		mut:  s.mut,
	}
}

func (s *ftmBool) atomic(tx TxBool) ftl.Closure {
	return func() error {
		s.mu.Lock()
		err := tx(s)
		s.mu.Unlock()
		return err
	}
}

func (s *ftmBool) Atomic(tx TxBool) ftl.Closure {
	return func() error {
		s.mu.Lock()
		err := tx(s.open())
		s.mu.Unlock()
		return err
	}
}

type TxBool func(FTMBool) error

func (f TxBool) Run(v bool) error {
	return f(newFTMBool(v))
}

func (f TxBool) Binds(bind func(TxBool, TxBool) TxBool,
	gs ...TxBool,
) TxBool {
	for _, g := range gs {
		f = bind(f, g)
	}
	return f
}

func (f TxBool) Checkpoint(gs ...TxBool) TxBool {
	return func(s FTMBool) error {
		var (
			inner = s.open()
			g     = inner.atomic(f)
			fs    = make([]ftl.Closure, len(gs))
		)
		for i := range gs {
			fs[i] = inner.atomic(gs[i])
		}
		return ftl.Closure.Seq(g, fs...)()
	}
}

func (f TxBool) Seq(gs ...TxBool) TxBool {
	return func(s FTMBool) error {
		var (
			fs = make([]ftl.Closure, len(gs))
			g  = f.ap(s)
		)
		for i := range gs {
			fs[i] = gs[i].ap(s)
		}
		return ftl.Closure.Seq(g, fs...)()
	}
}

// ap is unexported because `f.ap(s).Par(g)()` is
// very unsafe.
func (f TxBool) ap(s FTMBool) ftl.Closure {
	return func() error {
		return f(s)
	}
}

func (f TxBool) cond(p ftl.Predicate, exit bool) TxBool {
	return func(s FTMBool) error {
		for {
			if err := f(s); p(err) == exit {
				return err
			}
		}
	}
}

func (f TxBool) While(p ftl.Predicate) TxBool {
	return TxBool.cond(f, p, false)
}

func (f TxBool) Until(p ftl.Predicate) TxBool {
	return TxBool.cond(f, p, true)
}

func (f TxBool) Ite(p ftl.Predicate, g, z TxBool) TxBool {
	return func(s FTMBool) error {
		if err := f(s); p(err) {
			return g(s)
		} else {
			return z(s)
		}
	}
}

func (f TxBool) Mu(mu sync.Locker) TxBool {
	return func(s FTMBool) error {
		return f.ap(s).Mu(mu)()
	}
}

func (f TxBool) Once() TxBool {
	var once sync.Once
	return func(s FTMBool) error {
		var err error
		g := func() { err = f(s) }
		once.Do(g)
		return err
	}
}

// FTMByte exposes a thread-safe, mutable view into any
// value of type byte.
//
// Internally, nested mutexes are used instead of the
// usual retry mechanism.
type FTMByte interface {
	// Mut returns a pointer to a safely mutable byte.
	//
	// This reference must not escape the transaction
	// in which it was created.
	Mut() *byte

	// Discard any changes since the last checkpoint.
	Discard()

	open() FTMByte
	atomic(TxByte) ftl.Closure
}

// FTMByteV exposes an opaque view into any value of
// type byte. Reading or writing the value requires
// the use of a call to atomic.
type FTMByteV interface {
	Atomic(TxByte) ftl.Closure
}

type ftmByte struct {
	orig byte
	mut  *byte
	mu   sync.Mutex
}

func newFTMByte(v byte) *ftmByte {
	return &ftmByte{
		orig: v,
		mut:  &v,
	}
}

func NewFTMByteV(v byte) FTMByteV {
	return newFTMByte(v)
}

func (s *ftmByte) Mut() *byte {
	return s.mut
}

func (s *ftmByte) Discard() {
	*s.mut = s.orig
}

func (s *ftmByte) open() FTMByte {
	return &ftmByte{
		orig: *s.mut,
		mut:  s.mut,
	}
}

func (s *ftmByte) atomic(tx TxByte) ftl.Closure {
	return func() error {
		s.mu.Lock()
		err := tx(s)
		s.mu.Unlock()
		return err
	}
}

func (s *ftmByte) Atomic(tx TxByte) ftl.Closure {
	return func() error {
		s.mu.Lock()
		err := tx(s.open())
		s.mu.Unlock()
		return err
	}
}

type TxByte func(FTMByte) error

func (f TxByte) Run(v byte) error {
	return f(newFTMByte(v))
}

func (f TxByte) Binds(bind func(TxByte, TxByte) TxByte,
	gs ...TxByte,
) TxByte {
	for _, g := range gs {
		f = bind(f, g)
	}
	return f
}

func (f TxByte) Checkpoint(gs ...TxByte) TxByte {
	return func(s FTMByte) error {
		var (
			inner = s.open()
			g     = inner.atomic(f)
			fs    = make([]ftl.Closure, len(gs))
		)
		for i := range gs {
			fs[i] = inner.atomic(gs[i])
		}
		return ftl.Closure.Seq(g, fs...)()
	}
}

func (f TxByte) Seq(gs ...TxByte) TxByte {
	return func(s FTMByte) error {
		var (
			fs = make([]ftl.Closure, len(gs))
			g  = f.ap(s)
		)
		for i := range gs {
			fs[i] = gs[i].ap(s)
		}
		return ftl.Closure.Seq(g, fs...)()
	}
}

// ap is unexported because `f.ap(s).Par(g)()` is
// very unsafe.
func (f TxByte) ap(s FTMByte) ftl.Closure {
	return func() error {
		return f(s)
	}
}

func (f TxByte) cond(p ftl.Predicate, exit bool) TxByte {
	return func(s FTMByte) error {
		for {
			if err := f(s); p(err) == exit {
				return err
			}
		}
	}
}

func (f TxByte) While(p ftl.Predicate) TxByte {
	return TxByte.cond(f, p, false)
}

func (f TxByte) Until(p ftl.Predicate) TxByte {
	return TxByte.cond(f, p, true)
}

func (f TxByte) Ite(p ftl.Predicate, g, z TxByte) TxByte {
	return func(s FTMByte) error {
		if err := f(s); p(err) {
			return g(s)
		} else {
			return z(s)
		}
	}
}

func (f TxByte) Mu(mu sync.Locker) TxByte {
	return func(s FTMByte) error {
		return f.ap(s).Mu(mu)()
	}
}

func (f TxByte) Once() TxByte {
	var once sync.Once
	return func(s FTMByte) error {
		var err error
		g := func() { err = f(s) }
		once.Do(g)
		return err
	}
}

// FTMComplex128 exposes a thread-safe, mutable view into any
// value of type complex128.
//
// Internally, nested mutexes are used instead of the
// usual retry mechanism.
type FTMComplex128 interface {
	// Mut returns a pointer to a safely mutable complex128.
	//
	// This reference must not escape the transaction
	// in which it was created.
	Mut() *complex128

	// Discard any changes since the last checkpoint.
	Discard()

	open() FTMComplex128
	atomic(TxComplex128) ftl.Closure
}

// FTMComplex128V exposes an opaque view into any value of
// type complex128. Reading or writing the value requires
// the use of a call to atomic.
type FTMComplex128V interface {
	Atomic(TxComplex128) ftl.Closure
}

type ftmComplex128 struct {
	orig complex128
	mut  *complex128
	mu   sync.Mutex
}

func newFTMComplex128(v complex128) *ftmComplex128 {
	return &ftmComplex128{
		orig: v,
		mut:  &v,
	}
}

func NewFTMComplex128V(v complex128) FTMComplex128V {
	return newFTMComplex128(v)
}

func (s *ftmComplex128) Mut() *complex128 {
	return s.mut
}

func (s *ftmComplex128) Discard() {
	*s.mut = s.orig
}

func (s *ftmComplex128) open() FTMComplex128 {
	return &ftmComplex128{
		orig: *s.mut,
		mut:  s.mut,
	}
}

func (s *ftmComplex128) atomic(tx TxComplex128) ftl.Closure {
	return func() error {
		s.mu.Lock()
		err := tx(s)
		s.mu.Unlock()
		return err
	}
}

func (s *ftmComplex128) Atomic(tx TxComplex128) ftl.Closure {
	return func() error {
		s.mu.Lock()
		err := tx(s.open())
		s.mu.Unlock()
		return err
	}
}

type TxComplex128 func(FTMComplex128) error

func (f TxComplex128) Run(v complex128) error {
	return f(newFTMComplex128(v))
}

func (f TxComplex128) Binds(bind func(TxComplex128, TxComplex128) TxComplex128,
	gs ...TxComplex128,
) TxComplex128 {
	for _, g := range gs {
		f = bind(f, g)
	}
	return f
}

func (f TxComplex128) Checkpoint(gs ...TxComplex128) TxComplex128 {
	return func(s FTMComplex128) error {
		var (
			inner = s.open()
			g     = inner.atomic(f)
			fs    = make([]ftl.Closure, len(gs))
		)
		for i := range gs {
			fs[i] = inner.atomic(gs[i])
		}
		return ftl.Closure.Seq(g, fs...)()
	}
}

func (f TxComplex128) Seq(gs ...TxComplex128) TxComplex128 {
	return func(s FTMComplex128) error {
		var (
			fs = make([]ftl.Closure, len(gs))
			g  = f.ap(s)
		)
		for i := range gs {
			fs[i] = gs[i].ap(s)
		}
		return ftl.Closure.Seq(g, fs...)()
	}
}

// ap is unexported because `f.ap(s).Par(g)()` is
// very unsafe.
func (f TxComplex128) ap(s FTMComplex128) ftl.Closure {
	return func() error {
		return f(s)
	}
}

func (f TxComplex128) cond(p ftl.Predicate, exit bool) TxComplex128 {
	return func(s FTMComplex128) error {
		for {
			if err := f(s); p(err) == exit {
				return err
			}
		}
	}
}

func (f TxComplex128) While(p ftl.Predicate) TxComplex128 {
	return TxComplex128.cond(f, p, false)
}

func (f TxComplex128) Until(p ftl.Predicate) TxComplex128 {
	return TxComplex128.cond(f, p, true)
}

func (f TxComplex128) Ite(p ftl.Predicate, g, z TxComplex128) TxComplex128 {
	return func(s FTMComplex128) error {
		if err := f(s); p(err) {
			return g(s)
		} else {
			return z(s)
		}
	}
}

func (f TxComplex128) Mu(mu sync.Locker) TxComplex128 {
	return func(s FTMComplex128) error {
		return f.ap(s).Mu(mu)()
	}
}

func (f TxComplex128) Once() TxComplex128 {
	var once sync.Once
	return func(s FTMComplex128) error {
		var err error
		g := func() { err = f(s) }
		once.Do(g)
		return err
	}
}

// FTMComplex64 exposes a thread-safe, mutable view into any
// value of type complex64.
//
// Internally, nested mutexes are used instead of the
// usual retry mechanism.
type FTMComplex64 interface {
	// Mut returns a pointer to a safely mutable complex64.
	//
	// This reference must not escape the transaction
	// in which it was created.
	Mut() *complex64

	// Discard any changes since the last checkpoint.
	Discard()

	open() FTMComplex64
	atomic(TxComplex64) ftl.Closure
}

// FTMComplex64V exposes an opaque view into any value of
// type complex64. Reading or writing the value requires
// the use of a call to atomic.
type FTMComplex64V interface {
	Atomic(TxComplex64) ftl.Closure
}

type ftmComplex64 struct {
	orig complex64
	mut  *complex64
	mu   sync.Mutex
}

func newFTMComplex64(v complex64) *ftmComplex64 {
	return &ftmComplex64{
		orig: v,
		mut:  &v,
	}
}

func NewFTMComplex64V(v complex64) FTMComplex64V {
	return newFTMComplex64(v)
}

func (s *ftmComplex64) Mut() *complex64 {
	return s.mut
}

func (s *ftmComplex64) Discard() {
	*s.mut = s.orig
}

func (s *ftmComplex64) open() FTMComplex64 {
	return &ftmComplex64{
		orig: *s.mut,
		mut:  s.mut,
	}
}

func (s *ftmComplex64) atomic(tx TxComplex64) ftl.Closure {
	return func() error {
		s.mu.Lock()
		err := tx(s)
		s.mu.Unlock()
		return err
	}
}

func (s *ftmComplex64) Atomic(tx TxComplex64) ftl.Closure {
	return func() error {
		s.mu.Lock()
		err := tx(s.open())
		s.mu.Unlock()
		return err
	}
}

type TxComplex64 func(FTMComplex64) error

func (f TxComplex64) Run(v complex64) error {
	return f(newFTMComplex64(v))
}

func (f TxComplex64) Binds(bind func(TxComplex64, TxComplex64) TxComplex64,
	gs ...TxComplex64,
) TxComplex64 {
	for _, g := range gs {
		f = bind(f, g)
	}
	return f
}

func (f TxComplex64) Checkpoint(gs ...TxComplex64) TxComplex64 {
	return func(s FTMComplex64) error {
		var (
			inner = s.open()
			g     = inner.atomic(f)
			fs    = make([]ftl.Closure, len(gs))
		)
		for i := range gs {
			fs[i] = inner.atomic(gs[i])
		}
		return ftl.Closure.Seq(g, fs...)()
	}
}

func (f TxComplex64) Seq(gs ...TxComplex64) TxComplex64 {
	return func(s FTMComplex64) error {
		var (
			fs = make([]ftl.Closure, len(gs))
			g  = f.ap(s)
		)
		for i := range gs {
			fs[i] = gs[i].ap(s)
		}
		return ftl.Closure.Seq(g, fs...)()
	}
}

// ap is unexported because `f.ap(s).Par(g)()` is
// very unsafe.
func (f TxComplex64) ap(s FTMComplex64) ftl.Closure {
	return func() error {
		return f(s)
	}
}

func (f TxComplex64) cond(p ftl.Predicate, exit bool) TxComplex64 {
	return func(s FTMComplex64) error {
		for {
			if err := f(s); p(err) == exit {
				return err
			}
		}
	}
}

func (f TxComplex64) While(p ftl.Predicate) TxComplex64 {
	return TxComplex64.cond(f, p, false)
}

func (f TxComplex64) Until(p ftl.Predicate) TxComplex64 {
	return TxComplex64.cond(f, p, true)
}

func (f TxComplex64) Ite(p ftl.Predicate, g, z TxComplex64) TxComplex64 {
	return func(s FTMComplex64) error {
		if err := f(s); p(err) {
			return g(s)
		} else {
			return z(s)
		}
	}
}

func (f TxComplex64) Mu(mu sync.Locker) TxComplex64 {
	return func(s FTMComplex64) error {
		return f.ap(s).Mu(mu)()
	}
}

func (f TxComplex64) Once() TxComplex64 {
	var once sync.Once
	return func(s FTMComplex64) error {
		var err error
		g := func() { err = f(s) }
		once.Do(g)
		return err
	}
}

// FTMError exposes a thread-safe, mutable view into any
// value of type error.
//
// Internally, nested mutexes are used instead of the
// usual retry mechanism.
type FTMError interface {
	// Mut returns a pointer to a safely mutable error.
	//
	// This reference must not escape the transaction
	// in which it was created.
	Mut() *error

	// Discard any changes since the last checkpoint.
	Discard()

	open() FTMError
	atomic(TxError) ftl.Closure
}

// FTMErrorV exposes an opaque view into any value of
// type error. Reading or writing the value requires
// the use of a call to atomic.
type FTMErrorV interface {
	Atomic(TxError) ftl.Closure
}

type ftmError struct {
	orig error
	mut  *error
	mu   sync.Mutex
}

func newFTMError(v error) *ftmError {
	return &ftmError{
		orig: v,
		mut:  &v,
	}
}

func NewFTMErrorV(v error) FTMErrorV {
	return newFTMError(v)
}

func (s *ftmError) Mut() *error {
	return s.mut
}

func (s *ftmError) Discard() {
	*s.mut = s.orig
}

func (s *ftmError) open() FTMError {
	return &ftmError{
		orig: *s.mut,
		mut:  s.mut,
	}
}

func (s *ftmError) atomic(tx TxError) ftl.Closure {
	return func() error {
		s.mu.Lock()
		err := tx(s)
		s.mu.Unlock()
		return err
	}
}

func (s *ftmError) Atomic(tx TxError) ftl.Closure {
	return func() error {
		s.mu.Lock()
		err := tx(s.open())
		s.mu.Unlock()
		return err
	}
}

type TxError func(FTMError) error

func (f TxError) Run(v error) error {
	return f(newFTMError(v))
}

func (f TxError) Binds(bind func(TxError, TxError) TxError,
	gs ...TxError,
) TxError {
	for _, g := range gs {
		f = bind(f, g)
	}
	return f
}

func (f TxError) Checkpoint(gs ...TxError) TxError {
	return func(s FTMError) error {
		var (
			inner = s.open()
			g     = inner.atomic(f)
			fs    = make([]ftl.Closure, len(gs))
		)
		for i := range gs {
			fs[i] = inner.atomic(gs[i])
		}
		return ftl.Closure.Seq(g, fs...)()
	}
}

func (f TxError) Seq(gs ...TxError) TxError {
	return func(s FTMError) error {
		var (
			fs = make([]ftl.Closure, len(gs))
			g  = f.ap(s)
		)
		for i := range gs {
			fs[i] = gs[i].ap(s)
		}
		return ftl.Closure.Seq(g, fs...)()
	}
}

// ap is unexported because `f.ap(s).Par(g)()` is
// very unsafe.
func (f TxError) ap(s FTMError) ftl.Closure {
	return func() error {
		return f(s)
	}
}

func (f TxError) cond(p ftl.Predicate, exit bool) TxError {
	return func(s FTMError) error {
		for {
			if err := f(s); p(err) == exit {
				return err
			}
		}
	}
}

func (f TxError) While(p ftl.Predicate) TxError {
	return TxError.cond(f, p, false)
}

func (f TxError) Until(p ftl.Predicate) TxError {
	return TxError.cond(f, p, true)
}

func (f TxError) Ite(p ftl.Predicate, g, z TxError) TxError {
	return func(s FTMError) error {
		if err := f(s); p(err) {
			return g(s)
		} else {
			return z(s)
		}
	}
}

func (f TxError) Mu(mu sync.Locker) TxError {
	return func(s FTMError) error {
		return f.ap(s).Mu(mu)()
	}
}

func (f TxError) Once() TxError {
	var once sync.Once
	return func(s FTMError) error {
		var err error
		g := func() { err = f(s) }
		once.Do(g)
		return err
	}
}

// FTMFloat32 exposes a thread-safe, mutable view into any
// value of type float32.
//
// Internally, nested mutexes are used instead of the
// usual retry mechanism.
type FTMFloat32 interface {
	// Mut returns a pointer to a safely mutable float32.
	//
	// This reference must not escape the transaction
	// in which it was created.
	Mut() *float32

	// Discard any changes since the last checkpoint.
	Discard()

	open() FTMFloat32
	atomic(TxFloat32) ftl.Closure
}

// FTMFloat32V exposes an opaque view into any value of
// type float32. Reading or writing the value requires
// the use of a call to atomic.
type FTMFloat32V interface {
	Atomic(TxFloat32) ftl.Closure
}

type ftmFloat32 struct {
	orig float32
	mut  *float32
	mu   sync.Mutex
}

func newFTMFloat32(v float32) *ftmFloat32 {
	return &ftmFloat32{
		orig: v,
		mut:  &v,
	}
}

func NewFTMFloat32V(v float32) FTMFloat32V {
	return newFTMFloat32(v)
}

func (s *ftmFloat32) Mut() *float32 {
	return s.mut
}

func (s *ftmFloat32) Discard() {
	*s.mut = s.orig
}

func (s *ftmFloat32) open() FTMFloat32 {
	return &ftmFloat32{
		orig: *s.mut,
		mut:  s.mut,
	}
}

func (s *ftmFloat32) atomic(tx TxFloat32) ftl.Closure {
	return func() error {
		s.mu.Lock()
		err := tx(s)
		s.mu.Unlock()
		return err
	}
}

func (s *ftmFloat32) Atomic(tx TxFloat32) ftl.Closure {
	return func() error {
		s.mu.Lock()
		err := tx(s.open())
		s.mu.Unlock()
		return err
	}
}

type TxFloat32 func(FTMFloat32) error

func (f TxFloat32) Run(v float32) error {
	return f(newFTMFloat32(v))
}

func (f TxFloat32) Binds(bind func(TxFloat32, TxFloat32) TxFloat32,
	gs ...TxFloat32,
) TxFloat32 {
	for _, g := range gs {
		f = bind(f, g)
	}
	return f
}

func (f TxFloat32) Checkpoint(gs ...TxFloat32) TxFloat32 {
	return func(s FTMFloat32) error {
		var (
			inner = s.open()
			g     = inner.atomic(f)
			fs    = make([]ftl.Closure, len(gs))
		)
		for i := range gs {
			fs[i] = inner.atomic(gs[i])
		}
		return ftl.Closure.Seq(g, fs...)()
	}
}

func (f TxFloat32) Seq(gs ...TxFloat32) TxFloat32 {
	return func(s FTMFloat32) error {
		var (
			fs = make([]ftl.Closure, len(gs))
			g  = f.ap(s)
		)
		for i := range gs {
			fs[i] = gs[i].ap(s)
		}
		return ftl.Closure.Seq(g, fs...)()
	}
}

// ap is unexported because `f.ap(s).Par(g)()` is
// very unsafe.
func (f TxFloat32) ap(s FTMFloat32) ftl.Closure {
	return func() error {
		return f(s)
	}
}

func (f TxFloat32) cond(p ftl.Predicate, exit bool) TxFloat32 {
	return func(s FTMFloat32) error {
		for {
			if err := f(s); p(err) == exit {
				return err
			}
		}
	}
}

func (f TxFloat32) While(p ftl.Predicate) TxFloat32 {
	return TxFloat32.cond(f, p, false)
}

func (f TxFloat32) Until(p ftl.Predicate) TxFloat32 {
	return TxFloat32.cond(f, p, true)
}

func (f TxFloat32) Ite(p ftl.Predicate, g, z TxFloat32) TxFloat32 {
	return func(s FTMFloat32) error {
		if err := f(s); p(err) {
			return g(s)
		} else {
			return z(s)
		}
	}
}

func (f TxFloat32) Mu(mu sync.Locker) TxFloat32 {
	return func(s FTMFloat32) error {
		return f.ap(s).Mu(mu)()
	}
}

func (f TxFloat32) Once() TxFloat32 {
	var once sync.Once
	return func(s FTMFloat32) error {
		var err error
		g := func() { err = f(s) }
		once.Do(g)
		return err
	}
}

// FTMFloat64 exposes a thread-safe, mutable view into any
// value of type float64.
//
// Internally, nested mutexes are used instead of the
// usual retry mechanism.
type FTMFloat64 interface {
	// Mut returns a pointer to a safely mutable float64.
	//
	// This reference must not escape the transaction
	// in which it was created.
	Mut() *float64

	// Discard any changes since the last checkpoint.
	Discard()

	open() FTMFloat64
	atomic(TxFloat64) ftl.Closure
}

// FTMFloat64V exposes an opaque view into any value of
// type float64. Reading or writing the value requires
// the use of a call to atomic.
type FTMFloat64V interface {
	Atomic(TxFloat64) ftl.Closure
}

type ftmFloat64 struct {
	orig float64
	mut  *float64
	mu   sync.Mutex
}

func newFTMFloat64(v float64) *ftmFloat64 {
	return &ftmFloat64{
		orig: v,
		mut:  &v,
	}
}

func NewFTMFloat64V(v float64) FTMFloat64V {
	return newFTMFloat64(v)
}

func (s *ftmFloat64) Mut() *float64 {
	return s.mut
}

func (s *ftmFloat64) Discard() {
	*s.mut = s.orig
}

func (s *ftmFloat64) open() FTMFloat64 {
	return &ftmFloat64{
		orig: *s.mut,
		mut:  s.mut,
	}
}

func (s *ftmFloat64) atomic(tx TxFloat64) ftl.Closure {
	return func() error {
		s.mu.Lock()
		err := tx(s)
		s.mu.Unlock()
		return err
	}
}

func (s *ftmFloat64) Atomic(tx TxFloat64) ftl.Closure {
	return func() error {
		s.mu.Lock()
		err := tx(s.open())
		s.mu.Unlock()
		return err
	}
}

type TxFloat64 func(FTMFloat64) error

func (f TxFloat64) Run(v float64) error {
	return f(newFTMFloat64(v))
}

func (f TxFloat64) Binds(bind func(TxFloat64, TxFloat64) TxFloat64,
	gs ...TxFloat64,
) TxFloat64 {
	for _, g := range gs {
		f = bind(f, g)
	}
	return f
}

func (f TxFloat64) Checkpoint(gs ...TxFloat64) TxFloat64 {
	return func(s FTMFloat64) error {
		var (
			inner = s.open()
			g     = inner.atomic(f)
			fs    = make([]ftl.Closure, len(gs))
		)
		for i := range gs {
			fs[i] = inner.atomic(gs[i])
		}
		return ftl.Closure.Seq(g, fs...)()
	}
}

func (f TxFloat64) Seq(gs ...TxFloat64) TxFloat64 {
	return func(s FTMFloat64) error {
		var (
			fs = make([]ftl.Closure, len(gs))
			g  = f.ap(s)
		)
		for i := range gs {
			fs[i] = gs[i].ap(s)
		}
		return ftl.Closure.Seq(g, fs...)()
	}
}

// ap is unexported because `f.ap(s).Par(g)()` is
// very unsafe.
func (f TxFloat64) ap(s FTMFloat64) ftl.Closure {
	return func() error {
		return f(s)
	}
}

func (f TxFloat64) cond(p ftl.Predicate, exit bool) TxFloat64 {
	return func(s FTMFloat64) error {
		for {
			if err := f(s); p(err) == exit {
				return err
			}
		}
	}
}

func (f TxFloat64) While(p ftl.Predicate) TxFloat64 {
	return TxFloat64.cond(f, p, false)
}

func (f TxFloat64) Until(p ftl.Predicate) TxFloat64 {
	return TxFloat64.cond(f, p, true)
}

func (f TxFloat64) Ite(p ftl.Predicate, g, z TxFloat64) TxFloat64 {
	return func(s FTMFloat64) error {
		if err := f(s); p(err) {
			return g(s)
		} else {
			return z(s)
		}
	}
}

func (f TxFloat64) Mu(mu sync.Locker) TxFloat64 {
	return func(s FTMFloat64) error {
		return f.ap(s).Mu(mu)()
	}
}

func (f TxFloat64) Once() TxFloat64 {
	var once sync.Once
	return func(s FTMFloat64) error {
		var err error
		g := func() { err = f(s) }
		once.Do(g)
		return err
	}
}

// FTMInt exposes a thread-safe, mutable view into any
// value of type int.
//
// Internally, nested mutexes are used instead of the
// usual retry mechanism.
type FTMInt interface {
	// Mut returns a pointer to a safely mutable int.
	//
	// This reference must not escape the transaction
	// in which it was created.
	Mut() *int

	// Discard any changes since the last checkpoint.
	Discard()

	open() FTMInt
	atomic(TxInt) ftl.Closure
}

// FTMIntV exposes an opaque view into any value of
// type int. Reading or writing the value requires
// the use of a call to atomic.
type FTMIntV interface {
	Atomic(TxInt) ftl.Closure
}

type ftmInt struct {
	orig int
	mut  *int
	mu   sync.Mutex
}

func newFTMInt(v int) *ftmInt {
	return &ftmInt{
		orig: v,
		mut:  &v,
	}
}

func NewFTMIntV(v int) FTMIntV {
	return newFTMInt(v)
}

func (s *ftmInt) Mut() *int {
	return s.mut
}

func (s *ftmInt) Discard() {
	*s.mut = s.orig
}

func (s *ftmInt) open() FTMInt {
	return &ftmInt{
		orig: *s.mut,
		mut:  s.mut,
	}
}

func (s *ftmInt) atomic(tx TxInt) ftl.Closure {
	return func() error {
		s.mu.Lock()
		err := tx(s)
		s.mu.Unlock()
		return err
	}
}

func (s *ftmInt) Atomic(tx TxInt) ftl.Closure {
	return func() error {
		s.mu.Lock()
		err := tx(s.open())
		s.mu.Unlock()
		return err
	}
}

type TxInt func(FTMInt) error

func (f TxInt) Run(v int) error {
	return f(newFTMInt(v))
}

func (f TxInt) Binds(bind func(TxInt, TxInt) TxInt,
	gs ...TxInt,
) TxInt {
	for _, g := range gs {
		f = bind(f, g)
	}
	return f
}

func (f TxInt) Checkpoint(gs ...TxInt) TxInt {
	return func(s FTMInt) error {
		var (
			inner = s.open()
			g     = inner.atomic(f)
			fs    = make([]ftl.Closure, len(gs))
		)
		for i := range gs {
			fs[i] = inner.atomic(gs[i])
		}
		return ftl.Closure.Seq(g, fs...)()
	}
}

func (f TxInt) Seq(gs ...TxInt) TxInt {
	return func(s FTMInt) error {
		var (
			fs = make([]ftl.Closure, len(gs))
			g  = f.ap(s)
		)
		for i := range gs {
			fs[i] = gs[i].ap(s)
		}
		return ftl.Closure.Seq(g, fs...)()
	}
}

// ap is unexported because `f.ap(s).Par(g)()` is
// very unsafe.
func (f TxInt) ap(s FTMInt) ftl.Closure {
	return func() error {
		return f(s)
	}
}

func (f TxInt) cond(p ftl.Predicate, exit bool) TxInt {
	return func(s FTMInt) error {
		for {
			if err := f(s); p(err) == exit {
				return err
			}
		}
	}
}

func (f TxInt) While(p ftl.Predicate) TxInt {
	return TxInt.cond(f, p, false)
}

func (f TxInt) Until(p ftl.Predicate) TxInt {
	return TxInt.cond(f, p, true)
}

func (f TxInt) Ite(p ftl.Predicate, g, z TxInt) TxInt {
	return func(s FTMInt) error {
		if err := f(s); p(err) {
			return g(s)
		} else {
			return z(s)
		}
	}
}

func (f TxInt) Mu(mu sync.Locker) TxInt {
	return func(s FTMInt) error {
		return f.ap(s).Mu(mu)()
	}
}

func (f TxInt) Once() TxInt {
	var once sync.Once
	return func(s FTMInt) error {
		var err error
		g := func() { err = f(s) }
		once.Do(g)
		return err
	}
}

// FTMInt16 exposes a thread-safe, mutable view into any
// value of type int16.
//
// Internally, nested mutexes are used instead of the
// usual retry mechanism.
type FTMInt16 interface {
	// Mut returns a pointer to a safely mutable int16.
	//
	// This reference must not escape the transaction
	// in which it was created.
	Mut() *int16

	// Discard any changes since the last checkpoint.
	Discard()

	open() FTMInt16
	atomic(TxInt16) ftl.Closure
}

// FTMInt16V exposes an opaque view into any value of
// type int16. Reading or writing the value requires
// the use of a call to atomic.
type FTMInt16V interface {
	Atomic(TxInt16) ftl.Closure
}

type ftmInt16 struct {
	orig int16
	mut  *int16
	mu   sync.Mutex
}

func newFTMInt16(v int16) *ftmInt16 {
	return &ftmInt16{
		orig: v,
		mut:  &v,
	}
}

func NewFTMInt16V(v int16) FTMInt16V {
	return newFTMInt16(v)
}

func (s *ftmInt16) Mut() *int16 {
	return s.mut
}

func (s *ftmInt16) Discard() {
	*s.mut = s.orig
}

func (s *ftmInt16) open() FTMInt16 {
	return &ftmInt16{
		orig: *s.mut,
		mut:  s.mut,
	}
}

func (s *ftmInt16) atomic(tx TxInt16) ftl.Closure {
	return func() error {
		s.mu.Lock()
		err := tx(s)
		s.mu.Unlock()
		return err
	}
}

func (s *ftmInt16) Atomic(tx TxInt16) ftl.Closure {
	return func() error {
		s.mu.Lock()
		err := tx(s.open())
		s.mu.Unlock()
		return err
	}
}

type TxInt16 func(FTMInt16) error

func (f TxInt16) Run(v int16) error {
	return f(newFTMInt16(v))
}

func (f TxInt16) Binds(bind func(TxInt16, TxInt16) TxInt16,
	gs ...TxInt16,
) TxInt16 {
	for _, g := range gs {
		f = bind(f, g)
	}
	return f
}

func (f TxInt16) Checkpoint(gs ...TxInt16) TxInt16 {
	return func(s FTMInt16) error {
		var (
			inner = s.open()
			g     = inner.atomic(f)
			fs    = make([]ftl.Closure, len(gs))
		)
		for i := range gs {
			fs[i] = inner.atomic(gs[i])
		}
		return ftl.Closure.Seq(g, fs...)()
	}
}

func (f TxInt16) Seq(gs ...TxInt16) TxInt16 {
	return func(s FTMInt16) error {
		var (
			fs = make([]ftl.Closure, len(gs))
			g  = f.ap(s)
		)
		for i := range gs {
			fs[i] = gs[i].ap(s)
		}
		return ftl.Closure.Seq(g, fs...)()
	}
}

// ap is unexported because `f.ap(s).Par(g)()` is
// very unsafe.
func (f TxInt16) ap(s FTMInt16) ftl.Closure {
	return func() error {
		return f(s)
	}
}

func (f TxInt16) cond(p ftl.Predicate, exit bool) TxInt16 {
	return func(s FTMInt16) error {
		for {
			if err := f(s); p(err) == exit {
				return err
			}
		}
	}
}

func (f TxInt16) While(p ftl.Predicate) TxInt16 {
	return TxInt16.cond(f, p, false)
}

func (f TxInt16) Until(p ftl.Predicate) TxInt16 {
	return TxInt16.cond(f, p, true)
}

func (f TxInt16) Ite(p ftl.Predicate, g, z TxInt16) TxInt16 {
	return func(s FTMInt16) error {
		if err := f(s); p(err) {
			return g(s)
		} else {
			return z(s)
		}
	}
}

func (f TxInt16) Mu(mu sync.Locker) TxInt16 {
	return func(s FTMInt16) error {
		return f.ap(s).Mu(mu)()
	}
}

func (f TxInt16) Once() TxInt16 {
	var once sync.Once
	return func(s FTMInt16) error {
		var err error
		g := func() { err = f(s) }
		once.Do(g)
		return err
	}
}

// FTMInt32 exposes a thread-safe, mutable view into any
// value of type int32.
//
// Internally, nested mutexes are used instead of the
// usual retry mechanism.
type FTMInt32 interface {
	// Mut returns a pointer to a safely mutable int32.
	//
	// This reference must not escape the transaction
	// in which it was created.
	Mut() *int32

	// Discard any changes since the last checkpoint.
	Discard()

	open() FTMInt32
	atomic(TxInt32) ftl.Closure
}

// FTMInt32V exposes an opaque view into any value of
// type int32. Reading or writing the value requires
// the use of a call to atomic.
type FTMInt32V interface {
	Atomic(TxInt32) ftl.Closure
}

type ftmInt32 struct {
	orig int32
	mut  *int32
	mu   sync.Mutex
}

func newFTMInt32(v int32) *ftmInt32 {
	return &ftmInt32{
		orig: v,
		mut:  &v,
	}
}

func NewFTMInt32V(v int32) FTMInt32V {
	return newFTMInt32(v)
}

func (s *ftmInt32) Mut() *int32 {
	return s.mut
}

func (s *ftmInt32) Discard() {
	*s.mut = s.orig
}

func (s *ftmInt32) open() FTMInt32 {
	return &ftmInt32{
		orig: *s.mut,
		mut:  s.mut,
	}
}

func (s *ftmInt32) atomic(tx TxInt32) ftl.Closure {
	return func() error {
		s.mu.Lock()
		err := tx(s)
		s.mu.Unlock()
		return err
	}
}

func (s *ftmInt32) Atomic(tx TxInt32) ftl.Closure {
	return func() error {
		s.mu.Lock()
		err := tx(s.open())
		s.mu.Unlock()
		return err
	}
}

type TxInt32 func(FTMInt32) error

func (f TxInt32) Run(v int32) error {
	return f(newFTMInt32(v))
}

func (f TxInt32) Binds(bind func(TxInt32, TxInt32) TxInt32,
	gs ...TxInt32,
) TxInt32 {
	for _, g := range gs {
		f = bind(f, g)
	}
	return f
}

func (f TxInt32) Checkpoint(gs ...TxInt32) TxInt32 {
	return func(s FTMInt32) error {
		var (
			inner = s.open()
			g     = inner.atomic(f)
			fs    = make([]ftl.Closure, len(gs))
		)
		for i := range gs {
			fs[i] = inner.atomic(gs[i])
		}
		return ftl.Closure.Seq(g, fs...)()
	}
}

func (f TxInt32) Seq(gs ...TxInt32) TxInt32 {
	return func(s FTMInt32) error {
		var (
			fs = make([]ftl.Closure, len(gs))
			g  = f.ap(s)
		)
		for i := range gs {
			fs[i] = gs[i].ap(s)
		}
		return ftl.Closure.Seq(g, fs...)()
	}
}

// ap is unexported because `f.ap(s).Par(g)()` is
// very unsafe.
func (f TxInt32) ap(s FTMInt32) ftl.Closure {
	return func() error {
		return f(s)
	}
}

func (f TxInt32) cond(p ftl.Predicate, exit bool) TxInt32 {
	return func(s FTMInt32) error {
		for {
			if err := f(s); p(err) == exit {
				return err
			}
		}
	}
}

func (f TxInt32) While(p ftl.Predicate) TxInt32 {
	return TxInt32.cond(f, p, false)
}

func (f TxInt32) Until(p ftl.Predicate) TxInt32 {
	return TxInt32.cond(f, p, true)
}

func (f TxInt32) Ite(p ftl.Predicate, g, z TxInt32) TxInt32 {
	return func(s FTMInt32) error {
		if err := f(s); p(err) {
			return g(s)
		} else {
			return z(s)
		}
	}
}

func (f TxInt32) Mu(mu sync.Locker) TxInt32 {
	return func(s FTMInt32) error {
		return f.ap(s).Mu(mu)()
	}
}

func (f TxInt32) Once() TxInt32 {
	var once sync.Once
	return func(s FTMInt32) error {
		var err error
		g := func() { err = f(s) }
		once.Do(g)
		return err
	}
}

// FTMInt64 exposes a thread-safe, mutable view into any
// value of type int64.
//
// Internally, nested mutexes are used instead of the
// usual retry mechanism.
type FTMInt64 interface {
	// Mut returns a pointer to a safely mutable int64.
	//
	// This reference must not escape the transaction
	// in which it was created.
	Mut() *int64

	// Discard any changes since the last checkpoint.
	Discard()

	open() FTMInt64
	atomic(TxInt64) ftl.Closure
}

// FTMInt64V exposes an opaque view into any value of
// type int64. Reading or writing the value requires
// the use of a call to atomic.
type FTMInt64V interface {
	Atomic(TxInt64) ftl.Closure
}

type ftmInt64 struct {
	orig int64
	mut  *int64
	mu   sync.Mutex
}

func newFTMInt64(v int64) *ftmInt64 {
	return &ftmInt64{
		orig: v,
		mut:  &v,
	}
}

func NewFTMInt64V(v int64) FTMInt64V {
	return newFTMInt64(v)
}

func (s *ftmInt64) Mut() *int64 {
	return s.mut
}

func (s *ftmInt64) Discard() {
	*s.mut = s.orig
}

func (s *ftmInt64) open() FTMInt64 {
	return &ftmInt64{
		orig: *s.mut,
		mut:  s.mut,
	}
}

func (s *ftmInt64) atomic(tx TxInt64) ftl.Closure {
	return func() error {
		s.mu.Lock()
		err := tx(s)
		s.mu.Unlock()
		return err
	}
}

func (s *ftmInt64) Atomic(tx TxInt64) ftl.Closure {
	return func() error {
		s.mu.Lock()
		err := tx(s.open())
		s.mu.Unlock()
		return err
	}
}

type TxInt64 func(FTMInt64) error

func (f TxInt64) Run(v int64) error {
	return f(newFTMInt64(v))
}

func (f TxInt64) Binds(bind func(TxInt64, TxInt64) TxInt64,
	gs ...TxInt64,
) TxInt64 {
	for _, g := range gs {
		f = bind(f, g)
	}
	return f
}

func (f TxInt64) Checkpoint(gs ...TxInt64) TxInt64 {
	return func(s FTMInt64) error {
		var (
			inner = s.open()
			g     = inner.atomic(f)
			fs    = make([]ftl.Closure, len(gs))
		)
		for i := range gs {
			fs[i] = inner.atomic(gs[i])
		}
		return ftl.Closure.Seq(g, fs...)()
	}
}

func (f TxInt64) Seq(gs ...TxInt64) TxInt64 {
	return func(s FTMInt64) error {
		var (
			fs = make([]ftl.Closure, len(gs))
			g  = f.ap(s)
		)
		for i := range gs {
			fs[i] = gs[i].ap(s)
		}
		return ftl.Closure.Seq(g, fs...)()
	}
}

// ap is unexported because `f.ap(s).Par(g)()` is
// very unsafe.
func (f TxInt64) ap(s FTMInt64) ftl.Closure {
	return func() error {
		return f(s)
	}
}

func (f TxInt64) cond(p ftl.Predicate, exit bool) TxInt64 {
	return func(s FTMInt64) error {
		for {
			if err := f(s); p(err) == exit {
				return err
			}
		}
	}
}

func (f TxInt64) While(p ftl.Predicate) TxInt64 {
	return TxInt64.cond(f, p, false)
}

func (f TxInt64) Until(p ftl.Predicate) TxInt64 {
	return TxInt64.cond(f, p, true)
}

func (f TxInt64) Ite(p ftl.Predicate, g, z TxInt64) TxInt64 {
	return func(s FTMInt64) error {
		if err := f(s); p(err) {
			return g(s)
		} else {
			return z(s)
		}
	}
}

func (f TxInt64) Mu(mu sync.Locker) TxInt64 {
	return func(s FTMInt64) error {
		return f.ap(s).Mu(mu)()
	}
}

func (f TxInt64) Once() TxInt64 {
	var once sync.Once
	return func(s FTMInt64) error {
		var err error
		g := func() { err = f(s) }
		once.Do(g)
		return err
	}
}

// FTMInt8 exposes a thread-safe, mutable view into any
// value of type int8.
//
// Internally, nested mutexes are used instead of the
// usual retry mechanism.
type FTMInt8 interface {
	// Mut returns a pointer to a safely mutable int8.
	//
	// This reference must not escape the transaction
	// in which it was created.
	Mut() *int8

	// Discard any changes since the last checkpoint.
	Discard()

	open() FTMInt8
	atomic(TxInt8) ftl.Closure
}

// FTMInt8V exposes an opaque view into any value of
// type int8. Reading or writing the value requires
// the use of a call to atomic.
type FTMInt8V interface {
	Atomic(TxInt8) ftl.Closure
}

type ftmInt8 struct {
	orig int8
	mut  *int8
	mu   sync.Mutex
}

func newFTMInt8(v int8) *ftmInt8 {
	return &ftmInt8{
		orig: v,
		mut:  &v,
	}
}

func NewFTMInt8V(v int8) FTMInt8V {
	return newFTMInt8(v)
}

func (s *ftmInt8) Mut() *int8 {
	return s.mut
}

func (s *ftmInt8) Discard() {
	*s.mut = s.orig
}

func (s *ftmInt8) open() FTMInt8 {
	return &ftmInt8{
		orig: *s.mut,
		mut:  s.mut,
	}
}

func (s *ftmInt8) atomic(tx TxInt8) ftl.Closure {
	return func() error {
		s.mu.Lock()
		err := tx(s)
		s.mu.Unlock()
		return err
	}
}

func (s *ftmInt8) Atomic(tx TxInt8) ftl.Closure {
	return func() error {
		s.mu.Lock()
		err := tx(s.open())
		s.mu.Unlock()
		return err
	}
}

type TxInt8 func(FTMInt8) error

func (f TxInt8) Run(v int8) error {
	return f(newFTMInt8(v))
}

func (f TxInt8) Binds(bind func(TxInt8, TxInt8) TxInt8,
	gs ...TxInt8,
) TxInt8 {
	for _, g := range gs {
		f = bind(f, g)
	}
	return f
}

func (f TxInt8) Checkpoint(gs ...TxInt8) TxInt8 {
	return func(s FTMInt8) error {
		var (
			inner = s.open()
			g     = inner.atomic(f)
			fs    = make([]ftl.Closure, len(gs))
		)
		for i := range gs {
			fs[i] = inner.atomic(gs[i])
		}
		return ftl.Closure.Seq(g, fs...)()
	}
}

func (f TxInt8) Seq(gs ...TxInt8) TxInt8 {
	return func(s FTMInt8) error {
		var (
			fs = make([]ftl.Closure, len(gs))
			g  = f.ap(s)
		)
		for i := range gs {
			fs[i] = gs[i].ap(s)
		}
		return ftl.Closure.Seq(g, fs...)()
	}
}

// ap is unexported because `f.ap(s).Par(g)()` is
// very unsafe.
func (f TxInt8) ap(s FTMInt8) ftl.Closure {
	return func() error {
		return f(s)
	}
}

func (f TxInt8) cond(p ftl.Predicate, exit bool) TxInt8 {
	return func(s FTMInt8) error {
		for {
			if err := f(s); p(err) == exit {
				return err
			}
		}
	}
}

func (f TxInt8) While(p ftl.Predicate) TxInt8 {
	return TxInt8.cond(f, p, false)
}

func (f TxInt8) Until(p ftl.Predicate) TxInt8 {
	return TxInt8.cond(f, p, true)
}

func (f TxInt8) Ite(p ftl.Predicate, g, z TxInt8) TxInt8 {
	return func(s FTMInt8) error {
		if err := f(s); p(err) {
			return g(s)
		} else {
			return z(s)
		}
	}
}

func (f TxInt8) Mu(mu sync.Locker) TxInt8 {
	return func(s FTMInt8) error {
		return f.ap(s).Mu(mu)()
	}
}

func (f TxInt8) Once() TxInt8 {
	var once sync.Once
	return func(s FTMInt8) error {
		var err error
		g := func() { err = f(s) }
		once.Do(g)
		return err
	}
}

// FTMRune exposes a thread-safe, mutable view into any
// value of type rune.
//
// Internally, nested mutexes are used instead of the
// usual retry mechanism.
type FTMRune interface {
	// Mut returns a pointer to a safely mutable rune.
	//
	// This reference must not escape the transaction
	// in which it was created.
	Mut() *rune

	// Discard any changes since the last checkpoint.
	Discard()

	open() FTMRune
	atomic(TxRune) ftl.Closure
}

// FTMRuneV exposes an opaque view into any value of
// type rune. Reading or writing the value requires
// the use of a call to atomic.
type FTMRuneV interface {
	Atomic(TxRune) ftl.Closure
}

type ftmRune struct {
	orig rune
	mut  *rune
	mu   sync.Mutex
}

func newFTMRune(v rune) *ftmRune {
	return &ftmRune{
		orig: v,
		mut:  &v,
	}
}

func NewFTMRuneV(v rune) FTMRuneV {
	return newFTMRune(v)
}

func (s *ftmRune) Mut() *rune {
	return s.mut
}

func (s *ftmRune) Discard() {
	*s.mut = s.orig
}

func (s *ftmRune) open() FTMRune {
	return &ftmRune{
		orig: *s.mut,
		mut:  s.mut,
	}
}

func (s *ftmRune) atomic(tx TxRune) ftl.Closure {
	return func() error {
		s.mu.Lock()
		err := tx(s)
		s.mu.Unlock()
		return err
	}
}

func (s *ftmRune) Atomic(tx TxRune) ftl.Closure {
	return func() error {
		s.mu.Lock()
		err := tx(s.open())
		s.mu.Unlock()
		return err
	}
}

type TxRune func(FTMRune) error

func (f TxRune) Run(v rune) error {
	return f(newFTMRune(v))
}

func (f TxRune) Binds(bind func(TxRune, TxRune) TxRune,
	gs ...TxRune,
) TxRune {
	for _, g := range gs {
		f = bind(f, g)
	}
	return f
}

func (f TxRune) Checkpoint(gs ...TxRune) TxRune {
	return func(s FTMRune) error {
		var (
			inner = s.open()
			g     = inner.atomic(f)
			fs    = make([]ftl.Closure, len(gs))
		)
		for i := range gs {
			fs[i] = inner.atomic(gs[i])
		}
		return ftl.Closure.Seq(g, fs...)()
	}
}

func (f TxRune) Seq(gs ...TxRune) TxRune {
	return func(s FTMRune) error {
		var (
			fs = make([]ftl.Closure, len(gs))
			g  = f.ap(s)
		)
		for i := range gs {
			fs[i] = gs[i].ap(s)
		}
		return ftl.Closure.Seq(g, fs...)()
	}
}

// ap is unexported because `f.ap(s).Par(g)()` is
// very unsafe.
func (f TxRune) ap(s FTMRune) ftl.Closure {
	return func() error {
		return f(s)
	}
}

func (f TxRune) cond(p ftl.Predicate, exit bool) TxRune {
	return func(s FTMRune) error {
		for {
			if err := f(s); p(err) == exit {
				return err
			}
		}
	}
}

func (f TxRune) While(p ftl.Predicate) TxRune {
	return TxRune.cond(f, p, false)
}

func (f TxRune) Until(p ftl.Predicate) TxRune {
	return TxRune.cond(f, p, true)
}

func (f TxRune) Ite(p ftl.Predicate, g, z TxRune) TxRune {
	return func(s FTMRune) error {
		if err := f(s); p(err) {
			return g(s)
		} else {
			return z(s)
		}
	}
}

func (f TxRune) Mu(mu sync.Locker) TxRune {
	return func(s FTMRune) error {
		return f.ap(s).Mu(mu)()
	}
}

func (f TxRune) Once() TxRune {
	var once sync.Once
	return func(s FTMRune) error {
		var err error
		g := func() { err = f(s) }
		once.Do(g)
		return err
	}
}

// FTMString exposes a thread-safe, mutable view into any
// value of type string.
//
// Internally, nested mutexes are used instead of the
// usual retry mechanism.
type FTMString interface {
	// Mut returns a pointer to a safely mutable string.
	//
	// This reference must not escape the transaction
	// in which it was created.
	Mut() *string

	// Discard any changes since the last checkpoint.
	Discard()

	open() FTMString
	atomic(TxString) ftl.Closure
}

// FTMStringV exposes an opaque view into any value of
// type string. Reading or writing the value requires
// the use of a call to atomic.
type FTMStringV interface {
	Atomic(TxString) ftl.Closure
}

type ftmString struct {
	orig string
	mut  *string
	mu   sync.Mutex
}

func newFTMString(v string) *ftmString {
	return &ftmString{
		orig: v,
		mut:  &v,
	}
}

func NewFTMStringV(v string) FTMStringV {
	return newFTMString(v)
}

func (s *ftmString) Mut() *string {
	return s.mut
}

func (s *ftmString) Discard() {
	*s.mut = s.orig
}

func (s *ftmString) open() FTMString {
	return &ftmString{
		orig: *s.mut,
		mut:  s.mut,
	}
}

func (s *ftmString) atomic(tx TxString) ftl.Closure {
	return func() error {
		s.mu.Lock()
		err := tx(s)
		s.mu.Unlock()
		return err
	}
}

func (s *ftmString) Atomic(tx TxString) ftl.Closure {
	return func() error {
		s.mu.Lock()
		err := tx(s.open())
		s.mu.Unlock()
		return err
	}
}

type TxString func(FTMString) error

func (f TxString) Run(v string) error {
	return f(newFTMString(v))
}

func (f TxString) Binds(bind func(TxString, TxString) TxString,
	gs ...TxString,
) TxString {
	for _, g := range gs {
		f = bind(f, g)
	}
	return f
}

func (f TxString) Checkpoint(gs ...TxString) TxString {
	return func(s FTMString) error {
		var (
			inner = s.open()
			g     = inner.atomic(f)
			fs    = make([]ftl.Closure, len(gs))
		)
		for i := range gs {
			fs[i] = inner.atomic(gs[i])
		}
		return ftl.Closure.Seq(g, fs...)()
	}
}

func (f TxString) Seq(gs ...TxString) TxString {
	return func(s FTMString) error {
		var (
			fs = make([]ftl.Closure, len(gs))
			g  = f.ap(s)
		)
		for i := range gs {
			fs[i] = gs[i].ap(s)
		}
		return ftl.Closure.Seq(g, fs...)()
	}
}

// ap is unexported because `f.ap(s).Par(g)()` is
// very unsafe.
func (f TxString) ap(s FTMString) ftl.Closure {
	return func() error {
		return f(s)
	}
}

func (f TxString) cond(p ftl.Predicate, exit bool) TxString {
	return func(s FTMString) error {
		for {
			if err := f(s); p(err) == exit {
				return err
			}
		}
	}
}

func (f TxString) While(p ftl.Predicate) TxString {
	return TxString.cond(f, p, false)
}

func (f TxString) Until(p ftl.Predicate) TxString {
	return TxString.cond(f, p, true)
}

func (f TxString) Ite(p ftl.Predicate, g, z TxString) TxString {
	return func(s FTMString) error {
		if err := f(s); p(err) {
			return g(s)
		} else {
			return z(s)
		}
	}
}

func (f TxString) Mu(mu sync.Locker) TxString {
	return func(s FTMString) error {
		return f.ap(s).Mu(mu)()
	}
}

func (f TxString) Once() TxString {
	var once sync.Once
	return func(s FTMString) error {
		var err error
		g := func() { err = f(s) }
		once.Do(g)
		return err
	}
}

// FTMUint exposes a thread-safe, mutable view into any
// value of type uint.
//
// Internally, nested mutexes are used instead of the
// usual retry mechanism.
type FTMUint interface {
	// Mut returns a pointer to a safely mutable uint.
	//
	// This reference must not escape the transaction
	// in which it was created.
	Mut() *uint

	// Discard any changes since the last checkpoint.
	Discard()

	open() FTMUint
	atomic(TxUint) ftl.Closure
}

// FTMUintV exposes an opaque view into any value of
// type uint. Reading or writing the value requires
// the use of a call to atomic.
type FTMUintV interface {
	Atomic(TxUint) ftl.Closure
}

type ftmUint struct {
	orig uint
	mut  *uint
	mu   sync.Mutex
}

func newFTMUint(v uint) *ftmUint {
	return &ftmUint{
		orig: v,
		mut:  &v,
	}
}

func NewFTMUintV(v uint) FTMUintV {
	return newFTMUint(v)
}

func (s *ftmUint) Mut() *uint {
	return s.mut
}

func (s *ftmUint) Discard() {
	*s.mut = s.orig
}

func (s *ftmUint) open() FTMUint {
	return &ftmUint{
		orig: *s.mut,
		mut:  s.mut,
	}
}

func (s *ftmUint) atomic(tx TxUint) ftl.Closure {
	return func() error {
		s.mu.Lock()
		err := tx(s)
		s.mu.Unlock()
		return err
	}
}

func (s *ftmUint) Atomic(tx TxUint) ftl.Closure {
	return func() error {
		s.mu.Lock()
		err := tx(s.open())
		s.mu.Unlock()
		return err
	}
}

type TxUint func(FTMUint) error

func (f TxUint) Run(v uint) error {
	return f(newFTMUint(v))
}

func (f TxUint) Binds(bind func(TxUint, TxUint) TxUint,
	gs ...TxUint,
) TxUint {
	for _, g := range gs {
		f = bind(f, g)
	}
	return f
}

func (f TxUint) Checkpoint(gs ...TxUint) TxUint {
	return func(s FTMUint) error {
		var (
			inner = s.open()
			g     = inner.atomic(f)
			fs    = make([]ftl.Closure, len(gs))
		)
		for i := range gs {
			fs[i] = inner.atomic(gs[i])
		}
		return ftl.Closure.Seq(g, fs...)()
	}
}

func (f TxUint) Seq(gs ...TxUint) TxUint {
	return func(s FTMUint) error {
		var (
			fs = make([]ftl.Closure, len(gs))
			g  = f.ap(s)
		)
		for i := range gs {
			fs[i] = gs[i].ap(s)
		}
		return ftl.Closure.Seq(g, fs...)()
	}
}

// ap is unexported because `f.ap(s).Par(g)()` is
// very unsafe.
func (f TxUint) ap(s FTMUint) ftl.Closure {
	return func() error {
		return f(s)
	}
}

func (f TxUint) cond(p ftl.Predicate, exit bool) TxUint {
	return func(s FTMUint) error {
		for {
			if err := f(s); p(err) == exit {
				return err
			}
		}
	}
}

func (f TxUint) While(p ftl.Predicate) TxUint {
	return TxUint.cond(f, p, false)
}

func (f TxUint) Until(p ftl.Predicate) TxUint {
	return TxUint.cond(f, p, true)
}

func (f TxUint) Ite(p ftl.Predicate, g, z TxUint) TxUint {
	return func(s FTMUint) error {
		if err := f(s); p(err) {
			return g(s)
		} else {
			return z(s)
		}
	}
}

func (f TxUint) Mu(mu sync.Locker) TxUint {
	return func(s FTMUint) error {
		return f.ap(s).Mu(mu)()
	}
}

func (f TxUint) Once() TxUint {
	var once sync.Once
	return func(s FTMUint) error {
		var err error
		g := func() { err = f(s) }
		once.Do(g)
		return err
	}
}

// FTMUint16 exposes a thread-safe, mutable view into any
// value of type uint16.
//
// Internally, nested mutexes are used instead of the
// usual retry mechanism.
type FTMUint16 interface {
	// Mut returns a pointer to a safely mutable uint16.
	//
	// This reference must not escape the transaction
	// in which it was created.
	Mut() *uint16

	// Discard any changes since the last checkpoint.
	Discard()

	open() FTMUint16
	atomic(TxUint16) ftl.Closure
}

// FTMUint16V exposes an opaque view into any value of
// type uint16. Reading or writing the value requires
// the use of a call to atomic.
type FTMUint16V interface {
	Atomic(TxUint16) ftl.Closure
}

type ftmUint16 struct {
	orig uint16
	mut  *uint16
	mu   sync.Mutex
}

func newFTMUint16(v uint16) *ftmUint16 {
	return &ftmUint16{
		orig: v,
		mut:  &v,
	}
}

func NewFTMUint16V(v uint16) FTMUint16V {
	return newFTMUint16(v)
}

func (s *ftmUint16) Mut() *uint16 {
	return s.mut
}

func (s *ftmUint16) Discard() {
	*s.mut = s.orig
}

func (s *ftmUint16) open() FTMUint16 {
	return &ftmUint16{
		orig: *s.mut,
		mut:  s.mut,
	}
}

func (s *ftmUint16) atomic(tx TxUint16) ftl.Closure {
	return func() error {
		s.mu.Lock()
		err := tx(s)
		s.mu.Unlock()
		return err
	}
}

func (s *ftmUint16) Atomic(tx TxUint16) ftl.Closure {
	return func() error {
		s.mu.Lock()
		err := tx(s.open())
		s.mu.Unlock()
		return err
	}
}

type TxUint16 func(FTMUint16) error

func (f TxUint16) Run(v uint16) error {
	return f(newFTMUint16(v))
}

func (f TxUint16) Binds(bind func(TxUint16, TxUint16) TxUint16,
	gs ...TxUint16,
) TxUint16 {
	for _, g := range gs {
		f = bind(f, g)
	}
	return f
}

func (f TxUint16) Checkpoint(gs ...TxUint16) TxUint16 {
	return func(s FTMUint16) error {
		var (
			inner = s.open()
			g     = inner.atomic(f)
			fs    = make([]ftl.Closure, len(gs))
		)
		for i := range gs {
			fs[i] = inner.atomic(gs[i])
		}
		return ftl.Closure.Seq(g, fs...)()
	}
}

func (f TxUint16) Seq(gs ...TxUint16) TxUint16 {
	return func(s FTMUint16) error {
		var (
			fs = make([]ftl.Closure, len(gs))
			g  = f.ap(s)
		)
		for i := range gs {
			fs[i] = gs[i].ap(s)
		}
		return ftl.Closure.Seq(g, fs...)()
	}
}

// ap is unexported because `f.ap(s).Par(g)()` is
// very unsafe.
func (f TxUint16) ap(s FTMUint16) ftl.Closure {
	return func() error {
		return f(s)
	}
}

func (f TxUint16) cond(p ftl.Predicate, exit bool) TxUint16 {
	return func(s FTMUint16) error {
		for {
			if err := f(s); p(err) == exit {
				return err
			}
		}
	}
}

func (f TxUint16) While(p ftl.Predicate) TxUint16 {
	return TxUint16.cond(f, p, false)
}

func (f TxUint16) Until(p ftl.Predicate) TxUint16 {
	return TxUint16.cond(f, p, true)
}

func (f TxUint16) Ite(p ftl.Predicate, g, z TxUint16) TxUint16 {
	return func(s FTMUint16) error {
		if err := f(s); p(err) {
			return g(s)
		} else {
			return z(s)
		}
	}
}

func (f TxUint16) Mu(mu sync.Locker) TxUint16 {
	return func(s FTMUint16) error {
		return f.ap(s).Mu(mu)()
	}
}

func (f TxUint16) Once() TxUint16 {
	var once sync.Once
	return func(s FTMUint16) error {
		var err error
		g := func() { err = f(s) }
		once.Do(g)
		return err
	}
}

// FTMUint32 exposes a thread-safe, mutable view into any
// value of type uint32.
//
// Internally, nested mutexes are used instead of the
// usual retry mechanism.
type FTMUint32 interface {
	// Mut returns a pointer to a safely mutable uint32.
	//
	// This reference must not escape the transaction
	// in which it was created.
	Mut() *uint32

	// Discard any changes since the last checkpoint.
	Discard()

	open() FTMUint32
	atomic(TxUint32) ftl.Closure
}

// FTMUint32V exposes an opaque view into any value of
// type uint32. Reading or writing the value requires
// the use of a call to atomic.
type FTMUint32V interface {
	Atomic(TxUint32) ftl.Closure
}

type ftmUint32 struct {
	orig uint32
	mut  *uint32
	mu   sync.Mutex
}

func newFTMUint32(v uint32) *ftmUint32 {
	return &ftmUint32{
		orig: v,
		mut:  &v,
	}
}

func NewFTMUint32V(v uint32) FTMUint32V {
	return newFTMUint32(v)
}

func (s *ftmUint32) Mut() *uint32 {
	return s.mut
}

func (s *ftmUint32) Discard() {
	*s.mut = s.orig
}

func (s *ftmUint32) open() FTMUint32 {
	return &ftmUint32{
		orig: *s.mut,
		mut:  s.mut,
	}
}

func (s *ftmUint32) atomic(tx TxUint32) ftl.Closure {
	return func() error {
		s.mu.Lock()
		err := tx(s)
		s.mu.Unlock()
		return err
	}
}

func (s *ftmUint32) Atomic(tx TxUint32) ftl.Closure {
	return func() error {
		s.mu.Lock()
		err := tx(s.open())
		s.mu.Unlock()
		return err
	}
}

type TxUint32 func(FTMUint32) error

func (f TxUint32) Run(v uint32) error {
	return f(newFTMUint32(v))
}

func (f TxUint32) Binds(bind func(TxUint32, TxUint32) TxUint32,
	gs ...TxUint32,
) TxUint32 {
	for _, g := range gs {
		f = bind(f, g)
	}
	return f
}

func (f TxUint32) Checkpoint(gs ...TxUint32) TxUint32 {
	return func(s FTMUint32) error {
		var (
			inner = s.open()
			g     = inner.atomic(f)
			fs    = make([]ftl.Closure, len(gs))
		)
		for i := range gs {
			fs[i] = inner.atomic(gs[i])
		}
		return ftl.Closure.Seq(g, fs...)()
	}
}

func (f TxUint32) Seq(gs ...TxUint32) TxUint32 {
	return func(s FTMUint32) error {
		var (
			fs = make([]ftl.Closure, len(gs))
			g  = f.ap(s)
		)
		for i := range gs {
			fs[i] = gs[i].ap(s)
		}
		return ftl.Closure.Seq(g, fs...)()
	}
}

// ap is unexported because `f.ap(s).Par(g)()` is
// very unsafe.
func (f TxUint32) ap(s FTMUint32) ftl.Closure {
	return func() error {
		return f(s)
	}
}

func (f TxUint32) cond(p ftl.Predicate, exit bool) TxUint32 {
	return func(s FTMUint32) error {
		for {
			if err := f(s); p(err) == exit {
				return err
			}
		}
	}
}

func (f TxUint32) While(p ftl.Predicate) TxUint32 {
	return TxUint32.cond(f, p, false)
}

func (f TxUint32) Until(p ftl.Predicate) TxUint32 {
	return TxUint32.cond(f, p, true)
}

func (f TxUint32) Ite(p ftl.Predicate, g, z TxUint32) TxUint32 {
	return func(s FTMUint32) error {
		if err := f(s); p(err) {
			return g(s)
		} else {
			return z(s)
		}
	}
}

func (f TxUint32) Mu(mu sync.Locker) TxUint32 {
	return func(s FTMUint32) error {
		return f.ap(s).Mu(mu)()
	}
}

func (f TxUint32) Once() TxUint32 {
	var once sync.Once
	return func(s FTMUint32) error {
		var err error
		g := func() { err = f(s) }
		once.Do(g)
		return err
	}
}

// FTMUint64 exposes a thread-safe, mutable view into any
// value of type uint64.
//
// Internally, nested mutexes are used instead of the
// usual retry mechanism.
type FTMUint64 interface {
	// Mut returns a pointer to a safely mutable uint64.
	//
	// This reference must not escape the transaction
	// in which it was created.
	Mut() *uint64

	// Discard any changes since the last checkpoint.
	Discard()

	open() FTMUint64
	atomic(TxUint64) ftl.Closure
}

// FTMUint64V exposes an opaque view into any value of
// type uint64. Reading or writing the value requires
// the use of a call to atomic.
type FTMUint64V interface {
	Atomic(TxUint64) ftl.Closure
}

type ftmUint64 struct {
	orig uint64
	mut  *uint64
	mu   sync.Mutex
}

func newFTMUint64(v uint64) *ftmUint64 {
	return &ftmUint64{
		orig: v,
		mut:  &v,
	}
}

func NewFTMUint64V(v uint64) FTMUint64V {
	return newFTMUint64(v)
}

func (s *ftmUint64) Mut() *uint64 {
	return s.mut
}

func (s *ftmUint64) Discard() {
	*s.mut = s.orig
}

func (s *ftmUint64) open() FTMUint64 {
	return &ftmUint64{
		orig: *s.mut,
		mut:  s.mut,
	}
}

func (s *ftmUint64) atomic(tx TxUint64) ftl.Closure {
	return func() error {
		s.mu.Lock()
		err := tx(s)
		s.mu.Unlock()
		return err
	}
}

func (s *ftmUint64) Atomic(tx TxUint64) ftl.Closure {
	return func() error {
		s.mu.Lock()
		err := tx(s.open())
		s.mu.Unlock()
		return err
	}
}

type TxUint64 func(FTMUint64) error

func (f TxUint64) Run(v uint64) error {
	return f(newFTMUint64(v))
}

func (f TxUint64) Binds(bind func(TxUint64, TxUint64) TxUint64,
	gs ...TxUint64,
) TxUint64 {
	for _, g := range gs {
		f = bind(f, g)
	}
	return f
}

func (f TxUint64) Checkpoint(gs ...TxUint64) TxUint64 {
	return func(s FTMUint64) error {
		var (
			inner = s.open()
			g     = inner.atomic(f)
			fs    = make([]ftl.Closure, len(gs))
		)
		for i := range gs {
			fs[i] = inner.atomic(gs[i])
		}
		return ftl.Closure.Seq(g, fs...)()
	}
}

func (f TxUint64) Seq(gs ...TxUint64) TxUint64 {
	return func(s FTMUint64) error {
		var (
			fs = make([]ftl.Closure, len(gs))
			g  = f.ap(s)
		)
		for i := range gs {
			fs[i] = gs[i].ap(s)
		}
		return ftl.Closure.Seq(g, fs...)()
	}
}

// ap is unexported because `f.ap(s).Par(g)()` is
// very unsafe.
func (f TxUint64) ap(s FTMUint64) ftl.Closure {
	return func() error {
		return f(s)
	}
}

func (f TxUint64) cond(p ftl.Predicate, exit bool) TxUint64 {
	return func(s FTMUint64) error {
		for {
			if err := f(s); p(err) == exit {
				return err
			}
		}
	}
}

func (f TxUint64) While(p ftl.Predicate) TxUint64 {
	return TxUint64.cond(f, p, false)
}

func (f TxUint64) Until(p ftl.Predicate) TxUint64 {
	return TxUint64.cond(f, p, true)
}

func (f TxUint64) Ite(p ftl.Predicate, g, z TxUint64) TxUint64 {
	return func(s FTMUint64) error {
		if err := f(s); p(err) {
			return g(s)
		} else {
			return z(s)
		}
	}
}

func (f TxUint64) Mu(mu sync.Locker) TxUint64 {
	return func(s FTMUint64) error {
		return f.ap(s).Mu(mu)()
	}
}

func (f TxUint64) Once() TxUint64 {
	var once sync.Once
	return func(s FTMUint64) error {
		var err error
		g := func() { err = f(s) }
		once.Do(g)
		return err
	}
}

// FTMUint8 exposes a thread-safe, mutable view into any
// value of type uint8.
//
// Internally, nested mutexes are used instead of the
// usual retry mechanism.
type FTMUint8 interface {
	// Mut returns a pointer to a safely mutable uint8.
	//
	// This reference must not escape the transaction
	// in which it was created.
	Mut() *uint8

	// Discard any changes since the last checkpoint.
	Discard()

	open() FTMUint8
	atomic(TxUint8) ftl.Closure
}

// FTMUint8V exposes an opaque view into any value of
// type uint8. Reading or writing the value requires
// the use of a call to atomic.
type FTMUint8V interface {
	Atomic(TxUint8) ftl.Closure
}

type ftmUint8 struct {
	orig uint8
	mut  *uint8
	mu   sync.Mutex
}

func newFTMUint8(v uint8) *ftmUint8 {
	return &ftmUint8{
		orig: v,
		mut:  &v,
	}
}

func NewFTMUint8V(v uint8) FTMUint8V {
	return newFTMUint8(v)
}

func (s *ftmUint8) Mut() *uint8 {
	return s.mut
}

func (s *ftmUint8) Discard() {
	*s.mut = s.orig
}

func (s *ftmUint8) open() FTMUint8 {
	return &ftmUint8{
		orig: *s.mut,
		mut:  s.mut,
	}
}

func (s *ftmUint8) atomic(tx TxUint8) ftl.Closure {
	return func() error {
		s.mu.Lock()
		err := tx(s)
		s.mu.Unlock()
		return err
	}
}

func (s *ftmUint8) Atomic(tx TxUint8) ftl.Closure {
	return func() error {
		s.mu.Lock()
		err := tx(s.open())
		s.mu.Unlock()
		return err
	}
}

type TxUint8 func(FTMUint8) error

func (f TxUint8) Run(v uint8) error {
	return f(newFTMUint8(v))
}

func (f TxUint8) Binds(bind func(TxUint8, TxUint8) TxUint8,
	gs ...TxUint8,
) TxUint8 {
	for _, g := range gs {
		f = bind(f, g)
	}
	return f
}

func (f TxUint8) Checkpoint(gs ...TxUint8) TxUint8 {
	return func(s FTMUint8) error {
		var (
			inner = s.open()
			g     = inner.atomic(f)
			fs    = make([]ftl.Closure, len(gs))
		)
		for i := range gs {
			fs[i] = inner.atomic(gs[i])
		}
		return ftl.Closure.Seq(g, fs...)()
	}
}

func (f TxUint8) Seq(gs ...TxUint8) TxUint8 {
	return func(s FTMUint8) error {
		var (
			fs = make([]ftl.Closure, len(gs))
			g  = f.ap(s)
		)
		for i := range gs {
			fs[i] = gs[i].ap(s)
		}
		return ftl.Closure.Seq(g, fs...)()
	}
}

// ap is unexported because `f.ap(s).Par(g)()` is
// very unsafe.
func (f TxUint8) ap(s FTMUint8) ftl.Closure {
	return func() error {
		return f(s)
	}
}

func (f TxUint8) cond(p ftl.Predicate, exit bool) TxUint8 {
	return func(s FTMUint8) error {
		for {
			if err := f(s); p(err) == exit {
				return err
			}
		}
	}
}

func (f TxUint8) While(p ftl.Predicate) TxUint8 {
	return TxUint8.cond(f, p, false)
}

func (f TxUint8) Until(p ftl.Predicate) TxUint8 {
	return TxUint8.cond(f, p, true)
}

func (f TxUint8) Ite(p ftl.Predicate, g, z TxUint8) TxUint8 {
	return func(s FTMUint8) error {
		if err := f(s); p(err) {
			return g(s)
		} else {
			return z(s)
		}
	}
}

func (f TxUint8) Mu(mu sync.Locker) TxUint8 {
	return func(s FTMUint8) error {
		return f.ap(s).Mu(mu)()
	}
}

func (f TxUint8) Once() TxUint8 {
	var once sync.Once
	return func(s FTMUint8) error {
		var err error
		g := func() { err = f(s) }
		once.Do(g)
		return err
	}
}

// FTMUintptr exposes a thread-safe, mutable view into any
// value of type uintptr.
//
// Internally, nested mutexes are used instead of the
// usual retry mechanism.
type FTMUintptr interface {
	// Mut returns a pointer to a safely mutable uintptr.
	//
	// This reference must not escape the transaction
	// in which it was created.
	Mut() *uintptr

	// Discard any changes since the last checkpoint.
	Discard()

	open() FTMUintptr
	atomic(TxUintptr) ftl.Closure
}

// FTMUintptrV exposes an opaque view into any value of
// type uintptr. Reading or writing the value requires
// the use of a call to atomic.
type FTMUintptrV interface {
	Atomic(TxUintptr) ftl.Closure
}

type ftmUintptr struct {
	orig uintptr
	mut  *uintptr
	mu   sync.Mutex
}

func newFTMUintptr(v uintptr) *ftmUintptr {
	return &ftmUintptr{
		orig: v,
		mut:  &v,
	}
}

func NewFTMUintptrV(v uintptr) FTMUintptrV {
	return newFTMUintptr(v)
}

func (s *ftmUintptr) Mut() *uintptr {
	return s.mut
}

func (s *ftmUintptr) Discard() {
	*s.mut = s.orig
}

func (s *ftmUintptr) open() FTMUintptr {
	return &ftmUintptr{
		orig: *s.mut,
		mut:  s.mut,
	}
}

func (s *ftmUintptr) atomic(tx TxUintptr) ftl.Closure {
	return func() error {
		s.mu.Lock()
		err := tx(s)
		s.mu.Unlock()
		return err
	}
}

func (s *ftmUintptr) Atomic(tx TxUintptr) ftl.Closure {
	return func() error {
		s.mu.Lock()
		err := tx(s.open())
		s.mu.Unlock()
		return err
	}
}

type TxUintptr func(FTMUintptr) error

func (f TxUintptr) Run(v uintptr) error {
	return f(newFTMUintptr(v))
}

func (f TxUintptr) Binds(bind func(TxUintptr, TxUintptr) TxUintptr,
	gs ...TxUintptr,
) TxUintptr {
	for _, g := range gs {
		f = bind(f, g)
	}
	return f
}

func (f TxUintptr) Checkpoint(gs ...TxUintptr) TxUintptr {
	return func(s FTMUintptr) error {
		var (
			inner = s.open()
			g     = inner.atomic(f)
			fs    = make([]ftl.Closure, len(gs))
		)
		for i := range gs {
			fs[i] = inner.atomic(gs[i])
		}
		return ftl.Closure.Seq(g, fs...)()
	}
}

func (f TxUintptr) Seq(gs ...TxUintptr) TxUintptr {
	return func(s FTMUintptr) error {
		var (
			fs = make([]ftl.Closure, len(gs))
			g  = f.ap(s)
		)
		for i := range gs {
			fs[i] = gs[i].ap(s)
		}
		return ftl.Closure.Seq(g, fs...)()
	}
}

// ap is unexported because `f.ap(s).Par(g)()` is
// very unsafe.
func (f TxUintptr) ap(s FTMUintptr) ftl.Closure {
	return func() error {
		return f(s)
	}
}

func (f TxUintptr) cond(p ftl.Predicate, exit bool) TxUintptr {
	return func(s FTMUintptr) error {
		for {
			if err := f(s); p(err) == exit {
				return err
			}
		}
	}
}

func (f TxUintptr) While(p ftl.Predicate) TxUintptr {
	return TxUintptr.cond(f, p, false)
}

func (f TxUintptr) Until(p ftl.Predicate) TxUintptr {
	return TxUintptr.cond(f, p, true)
}

func (f TxUintptr) Ite(p ftl.Predicate, g, z TxUintptr) TxUintptr {
	return func(s FTMUintptr) error {
		if err := f(s); p(err) {
			return g(s)
		} else {
			return z(s)
		}
	}
}

func (f TxUintptr) Mu(mu sync.Locker) TxUintptr {
	return func(s FTMUintptr) error {
		return f.ap(s).Mu(mu)()
	}
}

func (f TxUintptr) Once() TxUintptr {
	var once sync.Once
	return func(s FTMUintptr) error {
		var err error
		g := func() { err = f(s) }
		once.Do(g)
		return err
	}
}
